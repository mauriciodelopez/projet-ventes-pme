# ğŸ“Š Projet Data Engineer : Analyse des Ventes d'une PME

Ce projet vise Ã  automatiser la collecte, la transformation et lâ€™analyse de donnÃ©es de ventes issues de fichiers CSV, en utilisant un environnement DockerisÃ© composÃ© de deux services : un pour lâ€™exÃ©cution des scripts ETL, un autre pour le stockage en base de donnÃ©es SQLite.

---

## ğŸ“ Arborescence du projet

```
projet-ventes-pme/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sales_data.db              # Base de donnÃ©es SQLite gÃ©nÃ©rÃ©e
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ resultats_analyse_ventes.txt  # RÃ©sumÃ© complet des analyses
â”‚   â”œâ”€â”€ analyse.sql                   # RequÃªtes SQL d'analyse
â”‚   â”œâ”€â”€ note_analyse.txt             # SynthÃ¨se des rÃ©sultats
â”‚   â”œâ”€â”€ schema_architecture.png      # SchÃ©ma de lâ€™architecture
â”‚   â””â”€â”€ schema_donnees.png           # MCD de la base de donnÃ©es
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ main.py                   # Script principal ETL + analyse
â”œâ”€â”€ Dockerfile                   # Image pour exÃ©cuter les scripts
â”œâ”€â”€ docker-compose.yml           # Orchestration des deux services
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â””â”€â”€ README.md                    # Documentation du projet (ce fichier)
```

---

## âš™ï¸ Technologies utilisÃ©es

- ğŸ Python 3.11
- ğŸ³ Docker & Docker Compose
- ğŸ§® SQLite
- ğŸ“¦ Pandas, Requests

---

## ğŸ§± Architecture du projet

Lâ€™architecture suit une logique **ETL (Extract - Transform - Load)** avec deux services distincts :

- `etl_scripts` : service Python pour tÃ©lÃ©charger les CSV, les transformer, charger en base et gÃ©nÃ©rer des analyses.
- `db_sqlite` : service contenant SQLite pour accÃ©der Ã  la base de donnÃ©es.

ğŸ“Œ **Volume Docker** partagÃ© : les deux services accÃ¨dent Ã  la base `sales_data.db` via un volume `db_data`.

ğŸ“· Voir les schÃ©mas dans `outputs/schema_architecture.png` et `outputs/schema_donnees.png`.

---

## ğŸš€ Lancer le projet

Assurez-vous dâ€™avoir **Docker** installÃ©.

```bash
docker compose up --build
```

Cela :
- TÃ©lÃ©charge les donnÃ©es CSV
- CrÃ©e les tables SQLite
- InsÃ¨re les donnÃ©es (sans doublon)
- GÃ©nÃ¨re automatiquement les fichiers dâ€™analyse

---

## ğŸ“‚ Fichiers gÃ©nÃ©rÃ©s automatiquement

- `sales_data.db` : base de donnÃ©es SQLite
- `outputs/resultats_analyse_ventes.txt` : analyse complÃ¨te (CA, ventes par produit, par ville)
- `outputs/analyse.sql` : requÃªtes SQL utilisÃ©es
- `outputs/note_analyse.txt` : note dâ€™analyse claire et concise

---

## ğŸ§  RÃ©sultats principaux

Voici un exemple de rÃ©sultats gÃ©nÃ©rÃ©s :

```text
ğŸ“Š ANALYSE DES VENTES ğŸ“Š

1ï¸âƒ£ Chiffre d'affaires total : 1220.00 â‚¬

2ï¸âƒ£ Ventes par produit :
- Produit E : 35 unitÃ©s
- Produit B : 27 unitÃ©s
...

3ï¸âƒ£ Ventes par ville :
- Marseille : 27 unitÃ©s
- Lyon : 21 unitÃ©s
...
```

---

## ğŸ“Œ Objectifs pÃ©dagogiques atteints

âœ… CrÃ©er une architecture Ã  deux services  
âœ… Automatiser un pipeline ETL complet  
âœ… GÃ©rer les encodages, doublons et relations SQL  
âœ… GÃ©nÃ©rer des rapports et les documenter  
âœ… Travailler en environnement DockerisÃ©

---

## ğŸ§  Auteur

ğŸ‘¨â€ğŸ’» **Mauricio Lopez**  
Projet rÃ©alisÃ© dans le cadre dâ€™un exercice de positionnement Data Engineer.
